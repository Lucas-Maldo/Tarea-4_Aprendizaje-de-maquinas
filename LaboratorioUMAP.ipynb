{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538431ff-d98e-4fdf-b580-9b429e7dddd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\python3.11.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/lucas/AppData/Local/Microsoft/WindowsApps/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd39f7eb-e2bc-40b0-b74f-601da61f90aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión reducida: 16\tPrecisión (Accuracy): 0.9563571428571429\n",
      "Dimensión reducida: 32\tPrecisión (Accuracy): 0.9547142857142857\n",
      "Dimensión reducida: 64\tPrecisión (Accuracy): 0.9549285714285715\n",
      "Dimensión reducida: 128\tPrecisión (Accuracy): 0.9552857142857143\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el conjunto de datos MNIST\n",
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "# Obtener los datos y las etiquetas\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reductor de dimensionalidad UMAP\n",
    "reducer = umap.UMAP()\n",
    "\n",
    "# Dimensiones reducidas a evaluar\n",
    "dimensions = [16, 32, 64, 128]\n",
    "\n",
    "for dim in dimensions:\n",
    "    # Reducción de dimensionalidad a 'dim' dimensiones\n",
    "    reducer.n_components = dim\n",
    "    X_train_reduced = reducer.fit_transform(X_train)\n",
    "    X_test_reduced = reducer.transform(X_test)\n",
    "\n",
    "    # Entrenar el clasificador k-NN\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train_reduced, y_train)\n",
    "\n",
    "    # Predecir las etiquetas del conjunto de prueba\n",
    "    y_pred = knn.predict(X_test_reduced)\n",
    "\n",
    "    # Calcular la precisión (accuracy)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Dimensión reducida: {dim}\\tPrecisión (Accuracy): {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884dce8e-50aa-4a73-adb5-6bd49f551922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99ef5f60-8f00-42a6-8b3f-a23b1370fd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 28, 28, 32)   320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 28, 28, 32)  128         ['conv1[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   multiple             0           ['batch_normalization[0][0]',    \n",
      "                                                                  'batch_normalization_1[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]',  \n",
      "                                                                  'embedding[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   multiple             0           ['re_lu[0][0]',                  \n",
      "                                                                  're_lu[1][0]',                  \n",
      "                                                                  're_lu[2][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 14, 14, 64)   18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 14, 14, 64)  256         ['conv2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3 (Conv2D)                 (None, 7, 7, 128)    73856       ['max_pooling2d[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 7, 7, 128)   512         ['conv3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['max_pooling2d[2][0]']          \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 256)          524544      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " embedding (BatchNormalization)  (None, 256)         1024        ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           2570        ['re_lu[3][0]']                  \n",
      "                                                                                                  \n",
      " tf.nn.softmax (TFOpLambda)     (None, 10)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 621,706\n",
      "Trainable params: 620,746\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_43\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 28, 28, 32)   320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 28, 28, 32)  128         ['conv1[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   multiple             0           ['batch_normalization[0][0]',    \n",
      "                                                                  'batch_normalization_1[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   multiple             0           ['re_lu[0][0]',                  \n",
      "                                                                  're_lu[1][0]',                  \n",
      "                                                                  're_lu[2][0]']                  \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 14, 14, 64)   18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 14, 14, 64)  256         ['conv2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3 (Conv2D)                 (None, 7, 7, 128)    73856       ['max_pooling2d[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 7, 7, 128)   512         ['conv3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['max_pooling2d[2][0]']          \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 256)          524544      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " embedding (BatchNormalization)  (None, 256)         1024        ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 619,136\n",
      "Trainable params: 618,176\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n",
      "(10000, 28, 28)\n",
      "Dimensión reducida: 8\tPrecisión (Accuracy): 0.8652\n",
      "Dimensión reducida: 16\tPrecisión (Accuracy): 0.8688\n",
      "Dimensión reducida: 32\tPrecisión (Accuracy): 0.87\n",
      "Dimensión reducida: 64\tPrecisión (Accuracy): 0.8536\n",
      "\n",
      "Accuracy por categoría (Espacio Reducido):\n",
      "Categoría 0: 0.00%, 0.00%, 0.00%, 0.00%\n",
      "Categoría 1: 91.00%, 91.00%, 91.00%, 91.00%\n",
      "Categoría 2: 84.00%, 84.00%, 84.00%, 84.00%\n",
      "Categoría 3: 85.00%, 85.00%, 85.00%, 85.00%\n",
      "Categoría 4: 86.00%, 86.00%, 86.00%, 86.00%\n",
      "Categoría 5: 93.00%, 93.00%, 93.00%, 93.00%\n",
      "Categoría 6: 78.00%, 78.00%, 78.00%, 78.00%\n",
      "Categoría 7: 82.00%, 82.00%, 82.00%, 82.00%\n",
      "Categoría 8: 85.00%, 85.00%, 85.00%, 85.00%\n",
      "Categoría 9: 76.00%, 76.00%, 76.00%, 76.00%\n",
      "Categoría 10: 90.00%, 90.00%, 90.00%, 90.00%\n",
      "Categoría 11: 84.00%, 84.00%, 84.00%, 84.00%\n",
      "Categoría 12: 65.00%, 65.00%, 65.00%, 65.00%\n",
      "Categoría 13: 97.00%, 97.00%, 97.00%, 97.00%\n",
      "Categoría 14: 88.00%, 88.00%, 88.00%, 88.00%\n",
      "Categoría 15: 89.00%, 89.00%, 89.00%, 89.00%\n",
      "Categoría 16: 85.00%, 85.00%, 85.00%, 85.00%\n",
      "Categoría 17: 74.00%, 74.00%, 74.00%, 74.00%\n",
      "Categoría 18: 88.00%, 88.00%, 88.00%, 88.00%\n",
      "Categoría 19: 93.00%, 93.00%, 93.00%, 93.00%\n",
      "Categoría 20: 64.00%, 64.00%, 64.00%, 64.00%\n",
      "Categoría 21: 94.00%, 94.00%, 94.00%, 94.00%\n",
      "Categoría 22: 95.00%, 95.00%, 95.00%, 95.00%\n",
      "Categoría 23: 97.00%, 97.00%, 97.00%, 97.00%\n",
      "Categoría 24: 93.00%, 93.00%, 93.00%, 93.00%\n",
      "Categoría 25: 78.00%, 78.00%, 78.00%, 78.00%\n"
     ]
    }
   ],
   "source": [
    "class SSearch:\n",
    "    def __init__(self, model_file, layer_name):\n",
    "        # Cargar el modelo\n",
    "        model = tf.keras.models.load_model(model_file)\n",
    "        model.summary()\n",
    "        # Definir el submodelo (capa de embedding)\n",
    "        output = model.get_layer(layer_name).output\n",
    "        self.sim_model = tf.keras.Model(model.input, output)\n",
    "        self.sim_model.summary()\n",
    "        self.mu = np.load(\"mean.npy\")\n",
    "    \n",
    "    def load_catalog(self, data_file, label_file):\n",
    "        self.data_catalog = np.load(data_file)\n",
    "        self.data_labels = np.load(label_file)\n",
    "        print(self.data_catalog.shape)\n",
    "    \n",
    "    def prepare_data(self, data):\n",
    "        prepared_data = np.expand_dims(data, axis=1)\n",
    "        prepared_data = prepared_data - self.mu\n",
    "        return prepared_data\n",
    "    \n",
    "    def compute_features(self, data):\n",
    "        data = self.prepare_data(data)\n",
    "        self.fv = self.sim_model.predict(data)\n",
    "        print(\"FV-shape {}\".format(self.fv.shape))\n",
    "        return self.fv\n",
    "    \n",
    "    def compute_features_on_catalog(self):\n",
    "        return self.compute_features(self.data_catalog)\n",
    "    \n",
    "    def ssearch_all(self):\n",
    "        _ = self.compute_features_on_catalog()\n",
    "        fv = self.fv\n",
    "        normfv = np.linalg.norm(fv, ord=2, axis=1, keepdims=True)\n",
    "        fv= fv/ normfv\n",
    "        sim = np.matmul(fv, np.transpose(fv))\n",
    "        idxq = np.random.randint(self.fv.shape[0])\n",
    "        sim_q = sim[idxq,:]\n",
    "        print(\"label {}\".format(self.data_labels[idxq]))\n",
    "        sort_idx = np.argsort(-sim_q)[:10]\n",
    "        print(self.data_labels[sort_idx])\n",
    "        self.visualize(sort_idx)\n",
    "    \n",
    "    def visualize(self, sort_idx):\n",
    "        size = 28\n",
    "        n = 10\n",
    "        image = np.ones((size, n*size), dtype= np.uint8)*255\n",
    "        i=0\n",
    "        for i in np.arange(n):\n",
    "            image[:, i*size:(i+1)*size] = self.data_catalog[sort_idx[i], :, :]\n",
    "            i = i+1\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ssearch = SSearch(\"emnist_model\", \"embedding\")\n",
    "    ssearch.load_catalog(\"test_emnist_images.npy\", \"test_emnist_labels.npy\")\n",
    "    \n",
    "    #Dividir los datos en entrenamiento y prueba\n",
    "    # Datos de entrenamiento: 1000 muestras por clase\n",
    "    train_samples_per_class= 1000\n",
    "    train_indices =[]\n",
    "    for i in range(26):\n",
    "        class_indices = np.where(ssearch.data_labels == i)[0]\n",
    "        train_indices.extend(class_indices[:train_samples_per_class])\n",
    "        \n",
    "    train_data = ssearch.data_catalog[train_indices]\n",
    "    train_labels = ssearch.data_labels[train_indices]\n",
    "    \n",
    "    \n",
    "    #Datos de prueba: 100 muestras por clase\n",
    "    test_samples_per_class = 100\n",
    "    test_indices =[]\n",
    "    for i in range(26):\n",
    "        class_indices = np.where(ssearch.data_labels == i)[0]\n",
    "        test_indices.extend(class_indices[-test_samples_per_class:])\n",
    "    \n",
    "    test_data = ssearch.data_catalog[test_indices]\n",
    "    test_labels = ssearch.data_labels[test_indices]\n",
    "# Reducción de dimensionalidad utilizando UMAP\n",
    "dimensions = [8,16,32,64]\n",
    "reduced_data = []\n",
    "acc = []\n",
    "red = []\n",
    "original_accuracy = []\n",
    "reduced_accuracy = [[] for _ in range(len(dimensions))]\n",
    "reduced_category_accuracy = np.zeros((26, len(dimensions)))\n",
    "for dim in dimensions:\n",
    "    train_data_reshape = train_data.reshape(train_data.shape[0], -1)\n",
    "    test_data_reshape = test_data.reshape(test_data.shape[0], -1)\n",
    "    reducer = umap.UMAP(n_components=dim)\n",
    "    reduced_train_data = reducer.fit_transform(train_data_reshape)\n",
    "    reduced_data.append(reduced_train_data)\n",
    "    reduced_test_data = reducer.transform(test_data_reshape)\n",
    "\n",
    "    # Entrenar el clasificador k-NN\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(reduced_train_data, train_labels)\n",
    "\n",
    "    # Predecir las etiquetas del conjunto de prueba\n",
    "    y_pred = knn.predict(reduced_test_data)\n",
    "\n",
    "    # Calcular la precisión (accuracy)\n",
    "    accuracy = accuracy_score(test_labels, y_pred)\n",
    "    print(f\"Dimensión reducida: {dim}\\tPrecisión (Accuracy): {accuracy}\")\n",
    "    \n",
    "    # Calcular el accuracy por categoría en el espacio reducido\n",
    "    for i in range(26):\n",
    "        category_indices = np.where(test_labels == i)[0]\n",
    "\n",
    "        if len(category_indices) > 0:\n",
    "            for j in range(len(dimensions)):\n",
    "                reduced_category_pred = y_pred[category_indices]\n",
    "                reduced_category_accuracy[i, j] = accuracy_score(test_labels[category_indices], reduced_category_pred)\n",
    "\n",
    "print(\"\\nAccuracy por categoría (Espacio Reducido):\")\n",
    "for i in range(26):\n",
    "    print(\"Categoría {}: {}\".format(i, \", \".join(\"{:.2f}%\".format(100 * acc) for acc in reduced_category_accuracy[i])))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467944a-a965-49c9-a20b-94a92fd2592c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
